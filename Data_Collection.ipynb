{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING WEB SCRAPING\n",
    "\n",
    "#For single recipe, taking nutrient info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION FOR WEB SCRAPING\n",
    "\n",
    "import time\n",
    "def get_recipe_data(url, nutrient_df, ingredient_df):\n",
    "    \"\"\"\n",
    "    Scrape allrecipes.com for information on the nutrient content and ingredients of each recipe\n",
    "    Based on the url, ingredients and nutrient content are extracted separately from the website.\n",
    "    \n",
    "    IN: url: URL of the specific recipe as a string\n",
    "    OUT: nutrient and ingredient dataframes with the information for the given recipe\n",
    "    \"\"\"\n",
    "    \n",
    "    #nutrition information\n",
    "    url_nutrition = url + 'fullrecipenutrition'\n",
    "    \n",
    "    r1 = requests.get(url_nutrition)\n",
    "    time.sleep(random.uniform(0,5))\n",
    "    soup1 = BeautifulSoup(r1.text, 'html.parser')\n",
    "    \n",
    "    #this is the div containing all the nutrition information\n",
    "    nutrition_info = soup1.find_all('div', class_='nutrition-row')\n",
    "    \n",
    "    nutrient_list = []\n",
    "    \n",
    "    recipe = soup1.find('h2')\n",
    "    if recipe is not None:\n",
    "        recipe = recipe.text\n",
    "        for n in nutrition_info:\n",
    "            name = n.find(class_ = 'nutrient-name').text\n",
    "            amount = n.find(class_ = 'nutrient-value').text\n",
    "            name = name[:name.index(':')]\n",
    "            nutrient_list.append({'nutrient': name, 'amount': amount, 'recipe': recipe, 'URL': url})\n",
    "\n",
    "    nutrients = pd.DataFrame(nutrient_list)\n",
    "    nutrient_df = nutrient_df.append(nutrients, sort=True)\n",
    "    \n",
    "    #ingredients\n",
    "    r2 = requests.get(url)\n",
    "    time.sleep(random.uniform(0,5)\n",
    "    soup2 = BeautifulSoup(r2.text, 'html.parser')\n",
    "    ingredient_info = soup2.find_all(class_='recipe-container-outer')\n",
    "    \n",
    "    ingredient_list = []\n",
    "    for i in ingredient_info:\n",
    "        ingredient = i.find_all('span', {'itemprop':'recipeIngredient'}, class_ = 'recipe-ingred_txt added')\n",
    "        for x in ingredient:\n",
    "            ingredient_list.append({'ingredient': x.text, 'URL':url})\n",
    "\n",
    "    ingredients = pd.DataFrame(ingredient_list)\n",
    "    ingredient_df = ingredient_df.append(ingredients, sort=True)\n",
    "    \n",
    "    return nutrient_df, ingredient_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the function\n",
    "url = 'https://www.allrecipes.com/recipe/18057/sweet-potato-casserole-ii/'\n",
    "nutrient_columns = ['URL', 'amount', 'nutrient', 'recipe']\n",
    "ingredient_columns = ['URL', 'ingredient']\n",
    "nutrient_df = pd.DataFrame(columns=nutrient_columns)\n",
    "ingredient_df = pd.DataFrame(columns=ingredient_columns)\n",
    "\n",
    "nutrient_df, ingredient_df = get_recipe_data(url, nutrient_df, ingredient_df)\n",
    "\n",
    "url2 = 'https://www.allrecipes.com/recipe/7589/allspice-cream-cheese-frosting/'\n",
    "nutrient_df, ingredient_df = get_recipe_data(url2, nutrient_df, ingredient_df)\n",
    "\n",
    "display(nutrient_df.head())\n",
    "display(nutrient_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dinner recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinner_url_df = pd.read_csv('data/recipeLists/dinner_url.csv')\n",
    "dinner_url_df.columns = [\"originGridUrl\", \"recipeName\", \"recipeURL\"]\n",
    "#pd.options.display.max_colwidth = 200\n",
    "#display(dinner_url_df['recipeURL'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dinner_url_df['recipeURL'] = dinner_url_df['recipeURL'].split(\"?\")[0]\n",
    "dinner_url_df['recipeURL'] = dinner_url_df['recipeURL'].astype(str).apply(lambda x: x.split(\"?\")[0])\n",
    "#dinner_url_df['recipeURLPrime'] = str(dinner_url_df['recipeURL']).split(\"?\")[0]\n",
    "pd.set_option('display.max_rows', None,'display.max_columns', None)\n",
    "#display(dinner_url_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinnerURLList = dinner_url_df.recipeURL.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinnerURLList[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_columns = ['URL', 'amount', 'nutrient', 'recipe']\n",
    "ingredient_columns = ['URL', 'ingredient']\n",
    "nutrient_df = pd.DataFrame(columns=nutrient_columns)\n",
    "ingredient_df = pd.DataFrame(columns=ingredient_columns)\n",
    "\n",
    "for url in dinnerURLList:\n",
    "    nutrient_df, ingredient_df = get_recipe_data(url, nutrient_df, ingredient_df)\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_df.to_csv(\"dinner_nutrient.csv\")\n",
    "ingredient_df.to_csv(\"dinner_ingredient.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinnerURLList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brunch recipes import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brunch_url_df = pd.read_csv('data/recipeLists/breakfast_brunch_url.csv')\n",
    "#The last row is \"Nan\" so we decided to drop it\n",
    "brunch_url_df = brunch_url_df.dropna()\n",
    "\n",
    "display(brunch_url_df.head())\n",
    "display(brunch_url_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brunch_url_df.columns = [\"originGridUrl\", \"recipeName\", \"recipeURL\"]\n",
    "#pd.options.display.max_colwidth = 200\n",
    "#display(dinner_url_df['recipeURL'].head())\n",
    "\n",
    "#dinner_url_df['recipeURL'] = dinner_url_df['recipeURL'].split(\"?\")[0]\n",
    "brunch_url_df['recipeURL'] = brunch_url_df['recipeURL'].astype(str).apply(lambda x: x.split(\"?\")[0])\n",
    "#dinner_url_df['recipeURLPrime'] = str(dinner_url_df['recipeURL']).split(\"?\")[0]\n",
    "pd.set_option('display.max_rows', None,'display.max_columns', None)\n",
    "#display(dinner_url_df.head())\n",
    "\n",
    "brunchURLList = brunch_url_df.recipeURL.tolist()\n",
    "\n",
    "brunchURLList[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_columns = ['URL', 'amount', 'nutrient', 'recipe']\n",
    "ingredient_columns = ['URL', 'ingredient']\n",
    "brunch_nutrient_df = pd.DataFrame(columns=nutrient_columns)\n",
    "brunch_ingredient_df = pd.DataFrame(columns=ingredient_columns)\n",
    "\n",
    "brunchURLList = brunchURLList[525:]\n",
    "brunch_length=str(len(brunchURLList))\n",
    "for url in range(len(brunchURLList)):\n",
    "    brunch_nutrient_df, brunch_ingredient_df = get_recipe_data(brunchURLList[url], brunch_nutrient_df, brunch_ingredient_df)\n",
    "    print(str(url+1) + \"/\" + brunch_length)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brunch_nutrient_df.to_csv(\"brunch_nutrient_525-.csv\")\n",
    "brunch_ingredient_df.to_csv(\"brunch_ingredient_525-.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brunchURLList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brunch_nutrient_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vegetarian Recipes Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegetarian_url_df = pd.read_csv('data/recipeLists/vegetarian_url.csv')\n",
    "#The last row is \"Nan\" so we decided to drop it\n",
    "vegetarian_url_df = vegetarian_url_df.dropna()\n",
    "\n",
    "display(vegetarian_url_df.head())\n",
    "display(vegetarian_url_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegetarian_url_df.columns = [\"originGridUrl\", \"recipeName\", \"recipeURL\"]\n",
    "#pd.options.display.max_colwidth = 200\n",
    "#display(dinner_url_df['recipeURL'].head())\n",
    "\n",
    "#dinner_url_df['recipeURL'] = dinner_url_df['recipeURL'].split(\"?\")[0]\n",
    "vegetarian_url_df['recipeURL'] = vegetarian_url_df['recipeURL'].astype(str).apply(lambda x: x.split(\"?\")[0])\n",
    "#dinner_url_df['recipeURLPrime'] = str(dinner_url_df['recipeURL']).split(\"?\")[0]\n",
    "pd.set_option('display.max_rows', None,'display.max_columns', None)\n",
    "#display(dinner_url_df.head())\n",
    "\n",
    "vegetarianURLList = vegetarian_url_df.recipeURL.tolist()\n",
    "\n",
    "vegetarianURLList[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_columns = ['URL', 'amount', 'nutrient', 'recipe']\n",
    "ingredient_columns = ['URL', 'ingredient']\n",
    "vegetarian_nutrient_df = pd.DataFrame(columns=nutrient_columns)\n",
    "vegetarian_ingredient_df = pd.DataFrame(columns=ingredient_columns)\n",
    "\n",
    "vegetarianURLList = vegetarianURLList\n",
    "vegetarian_length=str(len(vegetarianURLList))\n",
    "for url in range(len(vegetarianURLList)):\n",
    "    vegetarian_nutrient_df, vegetarian_ingredient_df = get_recipe_data(vegetarianURLList[url], vegetarian_nutrient_df, vegetarian_ingredient_df)\n",
    "    print(str(url+1) + \"/\" + vegetarian_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brunch_nutrient_df.to_csv(\"vegetarian_nutrient.csv\")\n",
    "brunch_ingredient_df.to_csv(\"vegetarian_ingredient.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
